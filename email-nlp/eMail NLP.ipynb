{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMail API\n",
    "\n",
    "run gmail.py to gain permission for gmail api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import base64\n",
    "\n",
    "import httplib2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from apiclient import discovery\n",
    "from oauth2client import client\n",
    "from oauth2client import tools\n",
    "from oauth2client.file import Storage\n",
    "\n",
    "try:\n",
    "    import argparse\n",
    "    flags = \\\n",
    "        argparse.ArgumentParser(parents=[tools.argparser]).parse_args()\n",
    "except ImportError:\n",
    "    flags = None\n",
    "\n",
    "# If modifying these scopes, delete your previously saved credentials\n",
    "# at ~/.credentials/gmail-python-quickstart.json\n",
    "\n",
    "SCOPES = 'https://www.googleapis.com/auth/gmail.readonly'\n",
    "CLIENT_SECRET_FILE = 'client_secret.json'\n",
    "APPLICATION_NAME = 'Gmail API Python Quickstart'\n",
    "\n",
    "\n",
    "def get_credentials():\n",
    "    home_dir = os.path.expanduser('~')\n",
    "    credential_dir = os.path.join(home_dir, '.credentials')\n",
    "    if not os.path.exists(credential_dir):\n",
    "        os.makedirs(credential_dir)\n",
    "    credential_path = os.path.join(credential_dir,\n",
    "                                   'gmail-python-quickstart.json')\n",
    "\n",
    "    store = Storage(credential_path)\n",
    "    credentials = store.get()\n",
    "    if not credentials or credentials.invalid:\n",
    "        flow = client.flow_from_clientsecrets(CLIENT_SECRET_FILE,\n",
    "                SCOPES)\n",
    "        flow.user_agent = APPLICATION_NAME\n",
    "        if flags:\n",
    "            credentials = tools.run_flow(flow, store, flags)\n",
    "        else:\n",
    "\n",
    "              # Needed only for compatibility with Python 2.6\n",
    "\n",
    "            credentials = tools.run(flow, store)\n",
    "        print('Storing credentials to ' + credential_path)\n",
    "    return credentials\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Shows basic usage of the Gmail API.\n",
    "\n",
    "    Creates a Gmail API service object and outputs a list of label names\n",
    "    of the user's Gmail account.\n",
    "    \"\"\"\n",
    "\n",
    "    credentials = get_credentials()\n",
    "    http = credentials.authorize(httplib2.Http())\n",
    "    service = discovery.build('gmail', 'v1', http=http)\n",
    "\n",
    "    results = service.users().labels().list(userId='me').execute()\n",
    "    labels = results.get('labels', [])\n",
    "\n",
    "    if not labels:\n",
    "        print('No labels found.')\n",
    "    else:\n",
    "        print('Labels:')\n",
    "        for label in labels:\n",
    "            print(label['name'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search GMail\n",
    "1. Get email from current userId and save to CSV file\n",
    "2. Get list of user's emails\n",
    "3. Get user's emails content\n",
    "4. Data preprocessing - remove new lines, tabs, numbers and save only letters\n",
    "5. Then, we found the top 5 email senders and filter the emails\n",
    "6. Translate messages to english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from apiclient import errors\n",
    "import csv\n",
    "import re\n",
    "import email\n",
    "import sys\n",
    "import collections\n",
    "from googletrans import Translator\n",
    "import string\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "def ListMessagesMatchingQuery(service, user_id, query=''):\n",
    "    try:\n",
    "        response = service.users().messages().list(userId=user_id,\n",
    "                q=query).execute()\n",
    "        messages = []\n",
    "        if 'messages' in response:\n",
    "            messages.extend(response['messages'])\n",
    "\n",
    "        while 'nextPageToken' in response:\n",
    "            page_token = response['nextPageToken']\n",
    "            response = service.users().messages().list(userId=user_id,\n",
    "                    q=query, pageToken=page_token).execute()\n",
    "            messages.extend(response['messages'])\n",
    "\n",
    "        return messages\n",
    "    except errors.HttpError, error:\n",
    "        print('An error occurred: %s' % error)\n",
    "\n",
    "\n",
    "def ListMessagesWithLabels(service, user_id, label_ids=[]):\n",
    "    try:\n",
    "        response = service.users().messages().list(userId=user_id,\n",
    "                labelIds=label_ids).execute()\n",
    "        messages = []\n",
    "        if 'messages' in response:\n",
    "            messages.extend(response['messages'])\n",
    "\n",
    "        while 'nextPageToken' in response:\n",
    "            page_token = response['nextPageToken']\n",
    "            response = service.users().messages().list(userId=user_id,\n",
    "                    labelIds=label_ids, pageToken=page_token).execute()\n",
    "            messages.extend(response['messages'])\n",
    "\n",
    "        return messages\n",
    "    except errors.HttpError, error:\n",
    "        print('An error occurred: %s' % error)\n",
    "\n",
    "\n",
    "def saveListToCsv(mydict, csvName):\n",
    "    with open(csvName + '.csv', 'wb') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for (key, value) in mydict.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "\n",
    "def getEmails(filename):\n",
    "    print('getting emails')\n",
    "    credentials = get_credentials()\n",
    "    http = credentials.authorize(httplib2.Http())\n",
    "    service = discovery.build('gmail', 'v1', http=http)\n",
    "    list = ListMessagesMatchingQuery(service, 'me', query='')\n",
    "    print(str(len(list)))\n",
    "    with open(filename + '.csv', 'wb') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for index in range(len(list)):\n",
    "            writer.writerow([list[index]['id'], list[index]['threadId'\n",
    "                            ]])\n",
    "    print('done')\n",
    "\n",
    "\n",
    "def find_between(s, first, last):\n",
    "    try:\n",
    "        start = s.index(first) + len(first)\n",
    "        end = s.index(last, start)\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def getEmailsMsgs(emailsListFileName, emailsBodyFileName):\n",
    "\n",
    "    # reading the emails list with the ids:\n",
    "\n",
    "    with open(emailsListFileName + '.csv', 'rb') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        mydict = dict(reader)\n",
    "    print('done reading the emails list')\n",
    "    credentials = get_credentials()\n",
    "    http = credentials.authorize(httplib2.Http())\n",
    "    service = discovery.build('gmail', 'v1', http=http)\n",
    "    \n",
    "    i = 0\n",
    "    result = []\n",
    "    for msgId in mydict:\n",
    "        i = i + 1\n",
    "        message = service.users().messages().get(userId='me', id=msgId,\n",
    "                format='raw').execute()\n",
    "        msg_str = base64.urlsafe_b64decode(message['raw'].encode('utf-8'\n",
    "                ))\n",
    "        mime_msg = email.message_from_string(msg_str)\n",
    "        fromMsg = find_between(mime_msg['from'], '<', '>').strip()\n",
    "        if fromMsg == '':\n",
    "            fromMsg = mime_msg['from']\n",
    "        bodyMsg = rec_get_payload(mime_msg).replace('\\r', ' '\n",
    "                ).replace('\\n', ' ').replace('\\t', ' ').replace(',', ' '\n",
    "                ).replace('.', ' ').replace('\"', ' ').replace('/', ' ')\n",
    "        try:\n",
    "            bodyMsg = bodyMsg.decode('Windows-1255').encode('utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "        if '<html>' in bodyMsg:\n",
    "            bodyMsg = bodyMsg[:bodyMsg.index('<html>')]\n",
    "        result.append([fromMsg, bodyMsg])\n",
    "        print('msg num: ' + str(i))\n",
    "\n",
    "        with open('test.csv', 'wb') as myfile:\n",
    "            wr = csv.writer(myfile)\n",
    "            wr.writerows(result)\n",
    "    print('done decoding')\n",
    "\n",
    "\n",
    "def rec_get_payload(mime_msg):\n",
    "    ans = ''\n",
    "    if mime_msg.is_multipart():\n",
    "        for p in mime_msg.get_payload():\n",
    "            if p.is_multipart():\n",
    "                ans = ans + rec_get_payload(p)\n",
    "            else:\n",
    "                ans = ans + p.get_payload()\n",
    "    else:\n",
    "        ans = ans + mime_msg.get_payload()\n",
    "    return ans\n",
    "\n",
    "\n",
    "def preapare_data(bodyOfEmailsFileName, clearFileName):    \n",
    "    csv.field_size_limit(sys.maxint)\n",
    "    with open(bodyOfEmailsFileName + '.csv', 'rb') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        with open(clearFileName + '.csv', 'wb') as csv_file2:\n",
    "            line = next(reader, None)\n",
    "            i = 0\n",
    "            while line:\n",
    "                writer = csv.writer(csv_file2)\n",
    "                print(i)\n",
    "                i = i + 1\n",
    "                editedLine = line[1]\n",
    "                for ch in ['&', '#','-','!','@','$','%','^','&','*','(',')','_','+','=','/','\\\\','?',':',';','~','1','2','3','4','5','6','7','8','9','>','<','|','{','}','[',']']:\n",
    "                    editedLine = editedLine.replace(ch, ' ')                \n",
    "                editedLine = re.sub(' +', ' ', editedLine)\n",
    "                writer.writerow([line[0].strip(), editedLine])\n",
    "                line = next(reader, None)\n",
    "\n",
    "\n",
    "def getTopSendsers(sourceFileName):    \n",
    "    csv.field_size_limit(sys.maxint)\n",
    "    with open(sourceFileName + '.csv', 'rb') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        line = next(reader, None)\n",
    "        i = 0\n",
    "        senders = []\n",
    "        while line:\n",
    "            print(i)\n",
    "            i = i + 1\n",
    "            sender = line[0]\n",
    "            senders.append(sender)\n",
    "            line = next(reader, None)        \n",
    "        counter = collections.Counter(senders)\n",
    "        print(counter)\n",
    "\n",
    "\n",
    "def filterBySenders(srcFileName, destinationFileName, senderlist):    \n",
    "    csv.field_size_limit(sys.maxint)\n",
    "    with open(srcFileName + '.csv', 'rb') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        with open(destinationFileName + '.csv', 'wb') as csv_file2:\n",
    "            line = next(reader, None)\n",
    "            i = 0\n",
    "            while line:\n",
    "                writer = csv.writer(csv_file2)\n",
    "                print(i)\n",
    "                i = i + 1\n",
    "                if line[0] in senderlist:\n",
    "                    writer.writerow([line[0].strip(), line[1]])\n",
    "                line = next(reader, None)\n",
    "\n",
    "\n",
    "def translateToEnglish(srcFilePath, destinationFileName, start, end):    \n",
    "    with open(srcFilePath + '.csv', 'rb') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        with open(destinationFileName + '.csv', 'ab') as csv_file2:\n",
    "            line = next(reader, None)\n",
    "            i = 0\n",
    "            while line:\n",
    "                writer = csv.writer(csv_file2)\n",
    "                print(i)\n",
    "                i = i + 1\n",
    "                line_text = (line[1])[0:4999]\n",
    "                try:\n",
    "                    if i > start and i <= end:\n",
    "                        translator = Translator()\n",
    "                        translated = translator.translate(line_text)                        \n",
    "                        printable = set(string.printable)\n",
    "                        translated_text = filter(lambda x: x \\\n",
    "                                in printable, translated.text)\n",
    "                        writer.writerow([line[0], translated_text])\n",
    "                    line = next(reader, None)\n",
    "                    if i > end:\n",
    "                        break\n",
    "                except:\n",
    "                    print('skipped: ' + str(i))\n",
    "\n",
    "def basicSatistics(fileName,senderlist):\n",
    "    csv.field_size_limit(sys.maxint)\n",
    "    with open(fileName + '.csv', 'rb') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        line = next(reader, None)\n",
    "        i = 0\n",
    "        sendersUniqueWords = {}\n",
    "        emailsLengthAVG=[]\n",
    "        #5 senders\n",
    "        sendersWords={}\n",
    "        for k in range(0,5):\n",
    "            sendersWords[senderlist[k]]=[]\n",
    "            sendersUniqueWords[senderlist[k]]=[]\n",
    "        allWords=[]\n",
    "        while (line):\n",
    "            print(i)\n",
    "            i = i + 1\n",
    "            sender = line[0]\n",
    "            splitEmail=line[1].split();\n",
    "            #numOfUniqeWords=collections.Counter(splitEmail)\n",
    "            allWords.append(splitEmail)\n",
    "            sendersWords[line[0]].append(len(splitEmail))\n",
    "            sendersUniqueWords[line[0]].append(splitEmail)\n",
    "            emailsLengthAVG.append(len(splitEmail))\n",
    "            line = next(reader, None)\n",
    "        uniqueCountPerSender=[]\n",
    "        for k in range(0,5):\n",
    "            key=senderlist[k]\n",
    "            dictionaryValues=sendersUniqueWords[key];\n",
    "            uniqueCountPerSender.append([key,collections.Counter(list(itertools.chain.from_iterable(dictionaryValues)))])\n",
    "        allWordsCollectionUniqueCount=collections.Counter(list(itertools.chain.from_iterable(allWords)))\n",
    "        numberOfWordsTotal = collections.Counter(list(itertools.chain.from_iterable(allWords)))        \n",
    "        with open(\"numberOfWordsTotal.txt\", \"wb\") as fp:\n",
    "            pickle.dump(numberOfWordsTotal, fp)\n",
    "        with open(\"allWordsCollectionUniqueCount.txt\", \"wb\") as fp:\n",
    "            pickle.dump(allWordsCollectionUniqueCount, fp)\n",
    "        with open(\"uniqueCountPerSender.txt\", \"wb\") as fp:\n",
    "            pickle.dump(uniqueCountPerSender, fp)\n",
    "        #for reading:\n",
    "        # with open(\"test.txt\", \"rb\") as fp:  # Unpickling\n",
    "        #     b = pickle.load(fp)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # main()\n",
    "    # getEmails('emailsListIDS')\n",
    "    # getEmailsMsgs('emailsListIDS','emailsBodyList')\n",
    "    # preapare_data('test','clearEmailsBodyList2')\n",
    "    # getTopSendsers('clearEmailsBodyList2')\n",
    "    # #I choose the 5 senders email addresses I want to extract from the whole DB\n",
    "    # senderlist=['dean@bgu.ac.il','peler@exchange.bgu.ac.il','bitahon@bgu.ac.il','career@bgu.ac.il','shanigu@bgu.ac.il']\n",
    "    # filterBySenders('clearEmailsBodyList2','filteredBySenders',senderlist)\n",
    "    # translateToEnglish('filteredBySenders','filteredBySendersTranslated',821,880)\n",
    "\n",
    "    print('done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
